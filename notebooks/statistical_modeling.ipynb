{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Desktop\\AlphaCare-Insurance-Analytics\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Add the path to the script if it's not in the same directory\n",
    "sys.path.append(\"../scripts\")  # Adjust this path\n",
    "\n",
    "from training import train_and_log_model, initialize_mlflow, explain_model_with_shap\n",
    "from utils import count_group_contribution, create_bar_chart, create_grouped_bar_chart, create_boxplot\n",
    "from data_prep import load_data, handle_missing_data, engineer_features, create_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/MachineLearningRating_v3.txt\"\n",
    "\n",
    "data = load_data(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data Cleaning\n",
    "\n",
    "This section focuses on ensuring the quality of the data through a series of cleaning steps.\n",
    "\n",
    "1. **Identifying Missing Values:**\n",
    "   The code identifies which columns have missing data. These missing values can impact the accuracy of our models, so we need to handle them carefully.\n",
    "\n",
    "2.  **Addressing Missing Data:**\n",
    "    *   Columns with substantial missing data (over 50%) are removed from the analysis because they donâ€™t offer enough reliable information.\n",
    "    *   Rows that contain missing values in columns that have very few missing values are removed to make sure we are working with a clean dataset.\n",
    "    *   For columns with a moderate amount of missing values, the missing values are filled using the most frequent value to preserve the data's shape and reduce any impact on the model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumberOfVehiclesInFleet    100.000000\n",
      "CrossBorder                 99.930207\n",
      "CustomValueEstimate         77.956560\n",
      "WrittenOff                  64.183810\n",
      "Converted                   64.183810\n",
      "Rebuilt                     64.183810\n",
      "NewVehicle                  15.327998\n",
      "Bank                        14.594670\n",
      "AccountType                  4.022806\n",
      "Gender                       0.953507\n",
      "MaritalStatus                0.825819\n",
      "mmcode                       0.055195\n",
      "VehicleType                  0.055195\n",
      "make                         0.055195\n",
      "VehicleIntroDate             0.055195\n",
      "NumberOfDoors                0.055195\n",
      "bodytype                     0.055195\n",
      "kilowatts                    0.055195\n",
      "cubiccapacity                0.055195\n",
      "Cylinders                    0.055195\n",
      "Model                        0.055195\n",
      "CapitalOutstanding           0.000200\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "olumn_na_rations = data.isna().mean()\n",
    "print(olumn_na_rations[olumn_na_rations > 0].sort_values(ascending=False) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Addressing this missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "data = handle_missing_data(data)\n",
    "# Finally check for the missing values\n",
    "column_na_rations = data.isna().mean()\n",
    "print(column_na_rations[column_na_rations > 0].sort_values(ascending=False) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Here, we create new features that may assist the model with predictions, using domain specific knowledge.\n",
    "\n",
    "1. **Calculating Optimal Premium:**\n",
    "   A new feature called `OptimalPremium` is introduced. It represents a premium value that ensures at least a break-even return for the company, based on the amount claimed and the original premium. We assume that a company wants to ensure that they have a positive return for each customer, and this feature allows them to do this effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = engineer_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          TotalClaims  TotalPremium  OptimalPremium\n",
      "451249  393092.105263    243.538333   393092.105263\n",
      "601844  376432.491228    562.617807   376432.491228\n",
      "818316  363343.421053   1065.027982   363343.421053\n",
      "173451  304338.657895    818.206140   304338.657895\n",
      "172766  302361.149123    825.392281   302361.149123\n",
      "402798  286686.431053    783.867018   286686.431053\n",
      "803349  269311.929825    806.181579   269311.929825\n",
      "904510  265789.473684   1060.473070   265789.473684\n",
      "920077  263157.632807    857.887193   263157.632807\n",
      "710484  261307.017544   1261.964035   261307.017544\n"
     ]
    }
   ],
   "source": [
    "#Check the result of the top 10 rows.\n",
    "print(data[['TotalClaims', 'TotalPremium', 'OptimalPremium']].sort_values(by='TotalClaims' , ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Encoding\n",
    "\n",
    "This step transforms categorical features into numerical representations, as most machine learning models need numerical data.\n",
    "\n",
    "Categorical features are transformed using Label Encoding to assign a numerical label for each category, this ensures that the model can work with the categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_features(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting\n",
    "\n",
    "The dataset is split into training and testing sets, where 80% of the data will be used to train the model and 20% of the data will be used to evaluate the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data 80-20\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models\n",
    "\n",
    "Here, we implement various machine learning models.\n",
    "\n",
    "1.  **Initializing MLflow:**\n",
    "    An MLflow tracking URI and experiment are initialized to manage and keep track of model training and evaluation.\n",
    "\n",
    "2.  **Training the models:**\n",
    "      The code sets up several machine learning models, including Linear Regression, Decision Tree Regressor, Random Forest Regressor, and Gradient Boosting Regressor. It will then train each model and record the results in the MLflow server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_r2 = -float('inf')  # Initialize as negative infinity\n",
    "best_mse = float('inf')  # Initialize MSE as positive infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Initialize mlflow tracking uri\n",
    "tracking_uri = \"notebook\"\n",
    "experiment_name = \"Optimum Price\"\n",
    "tracking_id = initialize_mlflow(uri=tracking_uri, experiment_name=experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LinearRegression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Desktop\\AlphaCare-Insurance-Analytics\\venv\\lib\\site-packages\\mlflow\\types\\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 701.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForestRegressor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Desktop\\AlphaCare-Insurance-Analytics\\venv\\lib\\site-packages\\mlflow\\types\\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GradientBoostingRegressor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Desktop\\AlphaCare-Insurance-Analytics\\venv\\lib\\site-packages\\mlflow\\types\\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 655.99it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DecisionTreeRegressor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Desktop\\AlphaCare-Insurance-Analytics\\venv\\lib\\site-packages\\mlflow\\types\\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 520.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train each model and log with MLflow\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    mse, r2, trained_model = train_and_log_model(model, model_name, tracking_id, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: DecisionTreeRegressor\n",
      "Best R2 Score: -0.11943651272459466\n",
      "Best MSE: 5491871.41892026\n"
     ]
    }
   ],
   "source": [
    " # Compare based on r2 score (or you can change to mse)\n",
    "if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_mse = mse\n",
    "        best_model = trained_model\n",
    "\n",
    "\n",
    "# Print out the best model's results\n",
    "print(f\"Best model: {best_model.__class__.__name__}\")\n",
    "print(f\"Best R2 Score: {best_r2}\")\n",
    "print(f\"Best MSE: {best_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Explain the model\n",
    "# Generate SHAP explanations for the best model\n",
    "shap_values = explain_model_with_shap(best_model, x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                              "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
